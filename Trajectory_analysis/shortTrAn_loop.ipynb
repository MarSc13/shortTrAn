{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import tifffile as tif\n",
    "import cv2\n",
    "from loadmat import loadmat_file as load\n",
    "from remove_single_part import remove_single_part as rsp\n",
    "from padding import padding as padding    \n",
    "from create_fields import create_fields as fields\n",
    "from calc_fields_out import calc_fields as calc\n",
    "from binning import binning\n",
    "from remove_isolated_px import remove_isolated_px as mask\n",
    "from smoothing import smoothing\n",
    "from SaveInputParameter import SaveInputShortTrAn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num = 20 #number of datasets to be evaluated\n",
    "input_path = '/Volumes/Vin/Python/shortTrAn/Trc_' #without '.mat'\n",
    "resultpath = '/Volumes/Vin/Python/shortTrAn/results'\n",
    "time_lag = 10 #timelag ms\n",
    "time_exp = 9 #time expose in ms\n",
    "scale = 160 #pixelation of camera (160 nm) or pixelation of simulation mask (10 nm) \n",
    "sigma = 26 #localisation precision in nm\n",
    "errcorr = 'No' #shall be error correction conducted? 'Yes' or 'No'\n",
    "\n",
    "\n",
    "scal = 160 #binning to px of 160 nm\n",
    "\n",
    "\n",
    "#Parameter for Filter1: Removal of pixels containing less entries than the threshold.\n",
    "threshold = 6 \n",
    "\n",
    "#Parameter for Filter2: Removal of isolated pixels.\n",
    "kdim = 3 #odd number, defines folding kernel . Largest number for cross kernel is 5.\n",
    "kshape='box' #cross or box (kernel). \n",
    "\n",
    "#Parameter for Filter3: Smoothing out.\n",
    "kdim_smoothing= 3 #odd number defines smoothing kernel.\n",
    "wdth_outliers = 2 #defines width of outlier.\n",
    "mode_outliers = 'gauss' #or 'remove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveInputShortTrAn(input_path, resultpath, time_lag, time_exp, scale,sigma,\n",
    "                       errcorr, scal, threshold, kdim, kshape, kdim_smoothing,\n",
    "                       wdth_outliers, mode_outliers)\n",
    "\n",
    "for N in range(1,Num+1):\n",
    "    \n",
    "    # LOADING AND PREPARTION OF THE DATA SETS FOR ANALYSIS\n",
    "    \n",
    "    path = (input_path + str(N))\n",
    "    resultpath = resultpath\n",
    "    \n",
    "    #Imports data and applies the unit transfomation to 1 nm per pixel.\n",
    "    a, b, tracs,tracs_unint16, trac_num, counts, tracs_unint16corr, trac_numcorr, dt = load(path,scale)\n",
    "\n",
    "    #Removal of all trajectories of an length shorter than 2 frames.\n",
    "    tracs_unint16corr, trac_numcorr = rsp(trac_num,counts,a,tracs_unint16corr,trac_numcorr)\n",
    "\n",
    "    #Padding. Creates additional space which is later used for the downscaling/binning.\n",
    "    x_min, x_max, y_min, y_max, a, tracs_unint16corr, x_length, y_length, shape\\\n",
    "    = padding(tracs_unint16corr, a, resultpath, N)\n",
    "    #Creation of multiple feature space containing the countfield, diffusiontensor(xx,xy,yx,yy) \n",
    "    #and directed motion (x,y).\n",
    "    pointfield,vectorfield_x,vectorfield_y,tensorfield_xx,tensorfield_xy,tensorfield_yx,tensorfield_yy=fields(shape)\n",
    "    \n",
    "    \n",
    "    #CALCULATION OF THE LOCAL DIFFUSION COEFFICIENTS AND SPEEDS\n",
    "    \n",
    "    #Calculation of the derivates for each position of a trajectory based on the positional information of \n",
    "    #the input data.\n",
    "    #Followed by the calculation of the directed motion and the tranfer of the pixel wise sum of the counts,  \n",
    "    #diffusion coefficients and the speeds in the multilayer feature space.\n",
    "    directory,tensorfield_xx,tensorfield_xy,tensorfield_yx,tensorfield_yy,vectorfield_x,vectorfield_y\\\n",
    "    =calc(a,time_lag,sigma,time_exp,path,resultpath,N,errcorr,pointfield,tracs_unint16corr,\n",
    "                 trac_numcorr,vectorfield_x,vectorfield_y,tensorfield_xx,tensorfield_xy,tensorfield_yx,tensorfield_yy)\n",
    "    \n",
    "    \n",
    "    #BINNING INTO LARGER LOCAL SQUARES\n",
    "    \n",
    "    #where to save\n",
    "    directory = resultpath + '/Trc' + str(N)\n",
    "    #directory = path_input + str(num) + '/Binning_200'\n",
    "    \n",
    "    #Downscaling/binning. The entries of the new pixelation contain the sum of the underlying pixelation which is \n",
    "    #is normalized by the number of contributing pixels.\n",
    "    scaled_pointfield,scaled_pointfield_inv,scaled_vectorfield_x,scaled_vectorfield_y,scaled_tensorfield_xx,\\\n",
    "    scaled_tensorfield_xy,scaled_tensorfield_yx,scaled_tensorfield_yy,scld_ten_xx,scld_ten_xy,scld_ten_yx,\\\n",
    "    scld_ten_yy,scld_vec_x,scld_vec_y=binning(scal,directory,pointfield,vectorfield_x,vectorfield_y,\n",
    "                                              tensorfield_xx,tensorfield_xy,tensorfield_yx,tensorfield_yy)\n",
    "    \n",
    "    \n",
    "    #APLLICATION OF SPATIAL FILTER SEQUENCE\n",
    "    \n",
    "    if not os.path.exists(directory+'/results_filtering'):\n",
    "        #print('Path does not exist')\n",
    "        os.mkdir(directory+'/results_filtering')\n",
    "        directory = directory+'/results_filtering/'\n",
    "    else:\n",
    "        directory = directory+'/results_filtering/'\n",
    "\n",
    "    #Filter #1 and #2. Removes all pixels which have less entries then threshold x and are isolated.\n",
    "    scld_count_mskd,scld_ten_xx_mskd,scld_ten_xy_mskd,scld_ten_yx_mskd,scld_ten_yy_mskd,scld_vec_x_mskd, \\\n",
    "        scld_vec_y_mskd=mask(kdim,kshape,threshold,directory,scaled_pointfield,scld_ten_xx,\n",
    "                                           scld_ten_xy,scld_ten_yx,scld_ten_yy,scld_vec_x,scld_vec_y)\n",
    "\n",
    "    #Filter #3. Smoothes entries to the surrounding pixels using a for contributing entries weighted average filter \n",
    "    #of an certain kernel size kdim.\n",
    "    scld_count_fil,scld_vec_x_fil,scld_vec_y_fil,scld_ten_xx_fil,scld_ten_xy_fil,scld_ten_yx_fil,scld_ten_yy_fil\\\n",
    "    =smoothing(kdim_smoothing,wdth_outliers,mode_outliers,directory,scaled_pointfield,scld_count_mskd,scld_vec_x_mskd, \n",
    "               scld_vec_y_mskd,scld_ten_xx_mskd,scld_ten_xy_mskd,scld_ten_yx_mskd,scld_ten_yy_mskd)\n",
    "\n",
    "    #Saves input parameter in text file:\n",
    "    txt = open(directory +'input_parameter.txt',\"w+\")\n",
    "    txt.write(directory+'N\\n')\n",
    "    txt.write('Number of datasets: '+str(N) + '\\n')\n",
    "    txt.write('Filter 1: Threshold '+str(threshold) + '\\n') \n",
    "    txt.write('Filter 2: Kernel dimension '+str(kdim) + ' and shape ' + kshape + ' kernel \\n')  \n",
    "    txt.write('Filter 3: Kernel size '+str(kdim_smoothing)+', width outlier '+str(wdth_outliers)+', '+mode_outliers)\n",
    "    txt.close()\n",
    "    \n",
    "    print('Finished cell ' +str(N))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
